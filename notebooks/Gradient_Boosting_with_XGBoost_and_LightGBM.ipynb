{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/zerotodeeplearning/ztdl-masterclasses/blob/master/notebooks/Gradient_Boosting_with_XGBoost_and_LightGBM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2bwH96hViwS7"
   },
   "source": [
    "## Learn with us: www.zerotodeeplearning.com\n",
    "\n",
    "Copyright © 2021: Zero to Deep Learning ® Catalit LLC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bFidPKNdkVPg"
   },
   "outputs": [],
   "source": [
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DvoukA2tkGV4"
   },
   "source": [
    "# Gradient Boosting with XGBoost and LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N_r-QBApVpI5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E3uToT-HVrXA"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/zerotodeeplearning/ztdl-masterclasses/master/data/australian_credit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "Ghb7PWZmV1SY",
    "outputId": "a4c7cceb-5f49-4737-e486-92599b9edea0"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "4Idz_ZvOV8t5",
    "outputId": "d5179977-53af-4415-9abc-3c46b98bd266"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "U8ndw9Xf3iB_",
    "outputId": "99b574a3-5d3f-46d1-aeb3-9535ba3b7d63"
   },
   "outputs": [],
   "source": [
    "y = df.pop('class')\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "MzrBjhp03TN1",
    "outputId": "25b245eb-b777-46bf-cee3-db81bb854b1c"
   },
   "outputs": [],
   "source": [
    "numerical_features = list(df.select_dtypes(include='number').columns)\n",
    "numerical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "lFR6UURa3bA0",
    "outputId": "7adfea3c-7aad-4ebf-ee5a-7b20158b0b9a"
   },
   "outputs": [],
   "source": [
    "categorical_features = list(df.select_dtypes(exclude='number').columns)\n",
    "categorical_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NVJBfdGT3rFZ"
   },
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xv4Z6OMD3u__"
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dlGT_ZHn343l"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "  df[numerical_features], y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PjVbZQ__4Fhm"
   },
   "outputs": [],
   "source": [
    "def train_eval(model):\n",
    "  model.fit(X_train, y_train)\n",
    "\n",
    "  train_score = model.score(X_train, y_train)\n",
    "  test_score = model.score(X_test, y_test)\n",
    "  return train_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "colab_type": "code",
    "id": "KXpgWq4f4UQa",
    "outputId": "9df427aa-780f-4ccf-e81a-7837b0dc939e"
   },
   "outputs": [],
   "source": [
    "models = [DummyClassifier(strategy='most_frequent'),\n",
    "          LogisticRegression(solver='liblinear'),\n",
    "          DecisionTreeClassifier()]\n",
    "\n",
    "res = []\n",
    "\n",
    "for model in models:\n",
    "  mname = model.__class__.__name__\n",
    "  tr, te = train_eval(model)\n",
    "  res.append([mname, tr, te])\n",
    "\n",
    "df_results = pd.DataFrame(res, columns=['model_name',\n",
    "                                        'train_accuracy',\n",
    "                                        'test_accuracy'])\n",
    "\n",
    "df_results.sort_values('test_accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fakvNLxR4XTM"
   },
   "source": [
    "## Exercise 1: Scikit-Learn\n",
    "\n",
    "Extend the above measurements with the following models from Scikit Learn:\n",
    "\n",
    "- Random Forest\n",
    "- Extra Trees\n",
    "- AdaBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hAUEkIZA54Cp"
   },
   "source": [
    "## Exercise 2: XGBoost with 1-hot encoded variables\n",
    "\n",
    "Let's use XGBoost to classify our data.\n",
    "\n",
    "- Import `XGBClassifier` from `xgboost`\n",
    "- create a new dataset called `df_one_hot` where all categorical variables are one-hot encoded\n",
    "- perform a train/test split again\n",
    "- re-train all the models previously trained on the new dataset\n",
    "- include `XGBClassifier` in the list of models\n",
    "- compare their scores\n",
    "- BONUS: use `GridSearchCV` to optimize the hyperparameters of `XGBClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_o8YtRoL9S3f"
   },
   "source": [
    "## Exercise 3: LightGBM\n",
    "\n",
    "Let's use LightGBM to classify our data.\n",
    "\n",
    "- import `LGBMClassifier` from `lightgbm`\n",
    "- train your best model on the one-hot encoded features\n",
    "- compare the results\n",
    "\n",
    "- BONUS:\n",
    "- create a new dataset called `df_cat_enc` where all categorical variables are encoded with the `OrdinalEncoder` from `sklearn.preprocessing`, while the numerical features are preserved\n",
    "- perform a new train/test split\n",
    "- train a lgbm model on this data. You will need to use the following code:\n",
    "```python\n",
    "ds_train = lgb.Dataset(X_train, label=y_train)\n",
    "model3 = lgb.train(params, ds_train, \n",
    "                   categorical_feature = categorical_features)\n",
    "```\n",
    "refer to the [documentation](https://lightgbm.readthedocs.io/en/latest/Python-Intro.html) if you're unsure about how to proceed for this step.\n",
    "- compare their scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOJWB9s6S9wS5YLk8la7mLZ",
   "include_colab_link": true,
   "name": "Gradient_Boosting_with_XGBoost_and_LightGBM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
