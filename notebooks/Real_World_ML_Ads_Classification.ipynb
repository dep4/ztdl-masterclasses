{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/zerotodeeplearning/ztdl-masterclasses/blob/master/notebooks/Real_World_ML_Ads_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2bwH96hViwS7"
   },
   "source": [
    "## Learn with us: www.zerotodeeplearning.com\n",
    "\n",
    "Copyright © 2021: Zero to Deep Learning ® Catalit LLC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bFidPKNdkVPg"
   },
   "outputs": [],
   "source": [
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DvoukA2tkGV4"
   },
   "source": [
    "# Real World ML Ads Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a long exercise with a complex dataset. It is intended to approximate a real world case where data is not clean and you need to compare several approaches and make decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T-uIz5xuU2Jz"
   },
   "source": [
    "## Exercise 1: Get the data\n",
    "\n",
    "Original Dataset from: https://www.kaggle.com/overflow012/playing-with-ads\n",
    "\n",
    "Mirrored for convenience at https://archive.org/download/playing-with-ads/playing-with-ads.zip\n",
    "\n",
    "\n",
    "catid: it's category of ads. Possible values:\n",
    "- 2 = Jobs\n",
    "- 3 = Real Estate\n",
    "\n",
    "subcatid: it's the subcategory of ads. Possibles values:\n",
    "- 2 = Apartment House for sale\n",
    "- 11 = Lawyers\n",
    "- 12 = Administrative - Secretary\n",
    "- 14 = Call cente\n",
    "- 15 = Building\n",
    "- 16 = Accounting finance\n",
    "- 17 = Education - Teachers\n",
    "- 19 = Customer Support\n",
    "- 20 = Bar and Restaurant\n",
    "- 21 = Biotechnology\n",
    "- 22 = Retail\n",
    "- 23 = Technical support\n",
    "- 24 = Work from home\n",
    "- 26 = Transport\n",
    "- 27 = Medicine - Health\n",
    "- 28 = fashion\n",
    "- 29 = Advertising - Marketing\n",
    "- 30 = Human Resources\n",
    "- 31 = Public relations\n",
    "- 32 = Sellers\n",
    "- 33 = Engineers - Architects\n",
    "- 34 = software\n",
    "- 35 = Wholesales\n",
    "- 51 = Apartment - House for rent\n",
    "- 122 = Other offers\n",
    "- 132 = Travels and tourism\n",
    "- 134 = Administration - Executives\n",
    "\n",
    "\n",
    "Use your knowledge of shell commands to download and unzip the dataset. (Hint: to pass a command to the shell use `!`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "3rLGx2gKUhT_",
    "outputId": "2c42885e-93bf-483a-e25a-006b5847767e"
   },
   "outputs": [],
   "source": [
    "#@title Update and load libraries\n",
    "!pip install -U -q fasttext\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nDPkeNNWApBT"
   },
   "source": [
    "## Exercise 2: Load the dataset\n",
    "\n",
    "- Load the dataset into a Pandas DataFrame\n",
    "- Explore it using the `.head()` and `.info()` methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HFyOP4s-4JEf"
   },
   "source": [
    "## Exercise 3: Explore the labels\n",
    "\n",
    "This dataset contains 2 possible labels:\n",
    "- `catid`\n",
    "- `subcatid`\n",
    "\n",
    "Count the number or samples for each of the labels.\n",
    "- What do you notice?\n",
    "- Are the classes balanced?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hH59reBjBNxl"
   },
   "source": [
    "## Exercise 4: Ad length exploration\n",
    "\n",
    "- Create a new variable that measures the length of an Ad in number of characters.\n",
    "- Display the distribution of lengths with a histogram. Do you notice anything?\n",
    "- Can we use this `ad_length` as a feature for classifiation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mmemc9cgmhOk"
   },
   "source": [
    "## Exercise 5: Naive Machine Learning\n",
    "\n",
    "- train the model on a sample of the data with 2000 ads\n",
    "- Build a simple pipeline that takes the ad and predicts the `subcatid`:\n",
    "  - Use a `TfidfVectorizer` for encoding the ads. You can use the `char` analyzer with `ngram_range = (1, 3)` and `max_features=2000`.\n",
    "  - Use a `LogisticRegression` model to classify them\n",
    "  - Assess the score using `model.score` and `confusion_matrix`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Lg8Dv3IKG5F"
   },
   "source": [
    "## Exercise 6: Ideas\n",
    "\n",
    "Now that you've created your first model, make a list of idea of things that you could try in order to improve the model. These ideas could involve:\n",
    "- data manipulation\n",
    "- feature engineering\n",
    "- model selection\n",
    "- tooling and infrastructure\n",
    "\n",
    "Generate at least 10 ideas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x-SbRENGKe-o"
   },
   "source": [
    "## Exercise 7: Assessing ideas\n",
    "\n",
    "Bucket your ideas into 3 groups:\n",
    "- EASY. These should be straightforward to code if you know the API and their execution should not take more than a few minutes.\n",
    "- MEDIUM. These could take a little longer to code and may take a bit more to execute. The whole experiment should be achievable within a few hours.\n",
    "- HARD. These are good ideas that are time consuming, either because the implementation is not straightforward, or because decision are involved (e.g. how to impute missing data or how to better deal with outliers) or because their evaluation will take a long time.\n",
    "\n",
    "- Make a plan of your next steps that involves doing all the easy ideas and possibly some of the medium ideas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hvlGQLxW_v6u"
   },
   "source": [
    "## Exercise 8: First Idea\n",
    "\n",
    "The first idea is to notice that there are some subcategories that have very few samples, and there may be duplicate ads. Let's get rid of both.\n",
    "\n",
    "- Create a new dataset called `dfclean` with the following properties:\n",
    "  - drop all rows of categories with less than 50 ads\n",
    "  - drop all duplicate ads (same `catid`, `value`, `subcatid`)\n",
    "  - double check the number of ads per subcategory id\n",
    "\n",
    "  You should get the following counts:\n",
    "\n",
    "  ```\n",
    "subcatid count\n",
    "27     15699\n",
    "34      8488\n",
    "33      8025\n",
    "122     4796\n",
    "32      4553\n",
    "19      3192\n",
    "29      3085\n",
    "132     2316\n",
    "2       1997\n",
    "16      1936\n",
    "15      1724\n",
    "31      1505\n",
    "17      1173\n",
    "20      1156\n",
    "30      1044\n",
    "134     1023\n",
    "12       939\n",
    "11       875\n",
    "26       748\n",
    "28       601\n",
    "51       572\n",
    "21       292\n",
    "23       142\n",
    "14        98\n",
    "35        97\n",
    "```\n",
    "\n",
    "You can go ahead and implement your first and easiest idea or follow along and implement this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oYX0ucytFCKp"
   },
   "source": [
    "## Exercise 9: Second idea\n",
    "\n",
    "Rebalancing data.\n",
    "\n",
    "Let's create a training set with balanced subcategories.\n",
    "\n",
    "- Split `dfclean` into train and test with a test size of 10000 and random state 0\n",
    "- Create a new dataset `dfsampled` from `dftrain` that contains 50 samples from each subcat ide. you can use the `.sample` method with `replace=False` for this.\n",
    "- Check the length of `dfsampled`, it should contain 1250 rows.\n",
    "\n",
    "You can go ahead and implement your next idea or follow along and implement this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v5ZAZV5FF0BE"
   },
   "source": [
    "## Exercise 10: Next idea\n",
    "\n",
    "Machine Learning on balanced data\n",
    "\n",
    "- Train the pipeline model you defined earlier on the rebalanced data.\n",
    "- Assess the performance on the test set using the accuracy score and the confusion matrix.\n",
    "- Did rebalancing the data help?\n",
    "\n",
    "You can go ahead and implement your next idea or follow along and implement this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JlamkkMVGpV1"
   },
   "source": [
    "It helped a little but performance is still pretty bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KTw_bkFom9pW"
   },
   "source": [
    "## Exercise 11: Next idea\n",
    "\n",
    "Tools\n",
    "\n",
    "Build some tools to make experimentation faster. Define 3 helper functions:\n",
    "- \n",
    "```python\n",
    "def calculate_scores(y_true, y_pred):\n",
    "    \"\"\"Returns the accuracy and F1 score\"\"\"\n",
    "    ...\n",
    "    return acc, f1\n",
    "```\n",
    "- \n",
    "```python\n",
    "def calculate_scores_train_val(y_train, y_pred_train, y_val, y_pred_val):\n",
    "    \"\"\"Returns accuracy and F1 score for both training and validation sets\"\"\"\n",
    "    ...\n",
    "    return at, av, ft, fv\n",
    "```\n",
    "- \n",
    "```python\n",
    "def train_val_model(model, model_name, X_train, y_train, X_val, y_val):\n",
    "    \"\"\"Trains and evaluates a model, return the results in a DataFrame\"\"\"\n",
    "    ...\n",
    "    return pd.DataFrame(results,\n",
    "                        columns=[model_name],\n",
    "                        index=['model',\n",
    "                               'accuracy_score_train',\n",
    "                               'accuracy_score_val',\n",
    "                               'f1_score_train',\n",
    "                               'f1_score_val',\n",
    "                               'train_time', 'pred_time'])\n",
    "  ```\n",
    "\n",
    "You can go ahead and implement your next idea or follow along and implement this one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sEYwbjjRH6XP"
   },
   "source": [
    "## Exercise12: Next idea\n",
    "\n",
    "Dummy Classifier\n",
    "\n",
    "Validate your tools by evaluating a pipeline with `TfidfVectorizer` and `DummyClassifier`.\n",
    "\n",
    "You can go ahead and implement your next idea or follow along and implement this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QbEnGjDMIQH8"
   },
   "source": [
    "## Exercise 13: Next idea\n",
    "\n",
    "Regularization\n",
    "\n",
    "Let's assess the influence of regularization strength on the model performance.\n",
    "\n",
    "- define a variable `Cs = [0.001, 0.01, 0.1, 1, 10, 100, 1000]` with a few values for regularization.\n",
    "- Iterate over the regularization values and for each value assess the performance of a pipeline with:\n",
    "  - \n",
    "  ```python\n",
    "  TfidfVectorizer(analyzer='char', \n",
    "                  ngram_range=(1, 3),\n",
    "                  max_features=1000)\n",
    "  ```\n",
    "  and\n",
    "  - \n",
    "  ```python\n",
    "  LogisticRegression(C=c, solver='liblinear')\n",
    "  ```\n",
    "- Accumulate the results into a `results` DataFrame\n",
    "\n",
    "You can go ahead and implement your next idea or follow along and implement this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q8PY-ZC6J2QL"
   },
   "source": [
    "## Exercise 14: Next idea\n",
    "\n",
    "Assess the results\n",
    "\n",
    "Display the results using a bar plot. Which regularization gives the best performance? Use that value from now on.\n",
    "\n",
    "You can go ahead and implement your next idea or follow along and implement this one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eBmESEmnKuds"
   },
   "source": [
    "## Exercise 15: Next idea\n",
    "\n",
    "Let's assess the influence of the `ngram_range` parameter.\n",
    "\n",
    "- Vary the `ngram_range` and keep everything else fixed.\n",
    "- Set the regularization strength to `C=10`.\n",
    "- Append the results to the `results` DataFrame\n",
    "- Display the results for comparison\n",
    "\n",
    "You can go ahead and implement your next idea or follow along and implement this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gf_eBdteLSkA"
   },
   "source": [
    "## Exercise 16: Next idea\n",
    "\n",
    "Let's assess the influence of the `max_features` parameter of the `TfidfVectorizer`.\n",
    "\n",
    "- Set the `ngram_range=(1, 3)`\n",
    "- Set the regularization strength to `C=10`.\n",
    "- Append the results to the `results` DataFrame\n",
    "- Display the results for comparison\n",
    "\n",
    "You can go ahead and implement your next idea or follow along and implement this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yHJTwoE5LnIJ"
   },
   "source": [
    "## Exercise 17: Next idea\n",
    "\n",
    "Let's change the number of minimum samples in the rebalanced dataset. In order to do this:\n",
    "- create new resampled datasets with `n_samples_range = [50, 100, 200, 500, 1000]`. Use `replace=True` because sometimes more samples per class are required than available.\n",
    "- Train a model with `ngram_range=(1, 3)`, `max_features=10000` and `C=10`\n",
    "- Append the results to the `results` DataFrame\n",
    "- Display the results for comparison\n",
    "\n",
    "You can go ahead and implement your next idea or follow along and implement this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QuWHjlSfNRiV"
   },
   "source": [
    "## Exercise 18: Next idea\n",
    "\n",
    "Noticing that the performance of my model keeps increasing as the number of samples goes up, let's extend the `n_samples_range` a bit further:\n",
    "- Repeat the above steps with `n_samples_range = [1000, 2000, 3000]`\n",
    "- Append the results to the `results` DataFrame\n",
    "- Display the results for comparison\n",
    "\n",
    "You can go ahead and implement your next idea or follow along and implement this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V_09kIs7OxzP"
   },
   "source": [
    "### Exercise 18: BONUS\n",
    "\n",
    "You may have noticed that the last calculations took a long time. Let's display the training and inference times for all the experiments so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kJbro32pPFio"
   },
   "source": [
    "## Exercise 19: Next idea\n",
    "\n",
    "Iiterate on different models and see which one has the best performance. Feel free to implement this one or your next best idea.\n",
    "\n",
    "To iterate on models:\n",
    "- Load all the necessary model classes from `sklearn`, `xgboost`, `lightgbm`. For example, try the following:\n",
    "  - Multinomial Naive Bayes\n",
    "  - TruncatedSVD + XGBoost\n",
    "  - TruncatedSVD + Light GBM\n",
    "  - Logistic regression with C=100\n",
    "  - Stochastic Gradient Descent with different lossess and different values for alpha\n",
    "- Make a list of model instances and iterate:\n",
    "  - Use `n_samples=1000`\n",
    "  - Use `ngram_range=(1, 3)`\n",
    "  - Use `max_features=20000`\n",
    "  - Tran the model on the resampled data\n",
    "  - Append the results to the `results` DataFrame\n",
    "  - Display the results for comparison\n",
    "\n",
    "You can go ahead and implement your next idea or follow along and implement this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H2oveJPkSBWF"
   },
   "source": [
    "## Exercise 20: Next idea\n",
    "\n",
    "Let's use the FastText embeddings, following the method outlined [here](https://github.com/facebookresearch/fastText/tree/master/python#text-classification-model).\n",
    "\n",
    "In order to do this, we will need to:\n",
    "- save the data to a text file containing a training sentence per line along with the labels \n",
    "- labels need to be words that are prefixed by the string `__label__`\n",
    "- train the model using `fasttext.train_supervised`\n",
    "\n",
    "In order to achieve the above, we will define helper functions:\n",
    "- \n",
    "```python\n",
    "def clean_text(s):\n",
    "    \"\"\"Returns a clean string of text by:\n",
    "      - lowercasing the text\n",
    "      - replacing newlines with spaces\n",
    "      - replacing any characters that is not alphanumeric with a space\n",
    "      - condencing multiple spaces to a single space\n",
    "    \"\"\"\n",
    "    return clean_s\n",
    "```\n",
    "- \n",
    "```python\n",
    "def join_labels(df):\n",
    "    return ('__label__'\n",
    "            + df['subcatid'].astype(str) \n",
    "            + \" , \"\n",
    "            + clean_text(df['value']))\n",
    "```\n",
    "- \n",
    "```python\n",
    "def save_to_txt(dfin, fname):\n",
    "    series = join_labels(dfin)\n",
    "    with open(fname, 'w') as fout:\n",
    "      fout.write('\\n'.join(series.values))\n",
    "```\n",
    "\n",
    "Notice that the API of FastText is different from Scikit Learn's API, so you will have to write some glue code to compare the results.\n",
    "\n",
    "Also, it may be worth comparing the performance of FastText when trained using the unbalanced traing set VS the rebalanced training set.\n",
    "\n",
    "You can go ahead and implement your next idea or follow along and implement this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gDjJTq18pjB3"
   },
   "source": [
    "## Exercise 21: Next idea\n",
    "\n",
    "Let's combine the FastText embeddings with LightGBM into a single model using Gensim.\n",
    "\n",
    "- download the FastText model using the `gensim.downloader`\n",
    "- encode all sentences into vectors using the following approach:\n",
    "    - remove newline characters and introduce spaces around punctuation in every sentence\n",
    "    - encode every word in the sentences with FastText\n",
    "    - average the FastText embeddings in each sentence so that you obtain a single average embedding for each sentence.\n",
    "- Train and evaluate a `LGBMClassifier` on the embedded sentences and compare the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TgGTLV-v9czf"
   },
   "source": [
    "## Conclusion and Next steps\n",
    "\n",
    "- Is your model good enough?\n",
    "- Can you deploy it?\n",
    "- What other things should you consider?\n",
    "- What are your next steps?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOJWB9s6S9wS5YLk8la7mLZ",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Real_World_ML_Ads_Classification.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
