{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/zerotodeeplearning/ztdl-masterclasses/blob/master/notebooks/Natural_Language_Processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2bwH96hViwS7"
   },
   "source": [
    "## Learn with us: www.zerotodeeplearning.com\n",
    "\n",
    "Copyright © 2021: Zero to Deep Learning ® Catalit LLC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bFidPKNdkVPg"
   },
   "outputs": [],
   "source": [
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DvoukA2tkGV4"
   },
   "source": [
    "# Natural Language Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jfXjY8HxSM9t"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "import gzip\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/zerotodeeplearning/ztdl-masterclasses/master/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_path = tf.keras.utils.get_file(\n",
    "    'rotten_tomatoes_positive_reviews.txt',\n",
    "    url + 'rotten_tomatoes_positive_reviews.txt.gz',\n",
    "    extract=True)\n",
    "neg_path = tf.keras.utils.get_file(\n",
    "    'rotten_tomatoes_negative_reviews.txt',\n",
    "    url + 'rotten_tomatoes_negative_reviews.txt.gz',\n",
    "    extract=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head {pos_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(pos_path) as fin:\n",
    "  pos_rev = fin.readlines()\n",
    "  pos_rev = [r.decode('utf-8') for r in pos_rev]\n",
    "\n",
    "with gzip.open(neg_path) as fin:\n",
    "  neg_rev = fin.readlines()\n",
    "  neg_rev = [r.decode('utf-8') for r in neg_rev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_rev[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_rev[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pos_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(neg_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = np.array(pos_rev + neg_rev)\n",
    "y = np.array([1]*len(pos_rev) + [0]*len(neg_rev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_train, docs_test, y_train, y_test = train_test_split(docs, y, test_size=0.15, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FY1GV79dWBCK"
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "so_58y8XXUYH"
   },
   "outputs": [],
   "source": [
    "X_train = vectorizer.fit_transform(docs_train)\n",
    "X_test = vectorizer.transform(docs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p2Pcg6z0Xoma"
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='liblinear', C=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "gO1_FkAWWjhb",
    "outputId": "f37cf513-605e-4606-85bd-75102b645d09"
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dljENizEWoLm",
    "outputId": "2f323a31-eb4a-4ab8-82c6-31a7de18bffb"
   },
   "outputs": [],
   "source": [
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uGS7WaFzWtyn",
    "outputId": "bd642f85-b9d2-4cd2-ec3e-0800647864d1"
   },
   "outputs": [],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Feature importances\n",
    "\n",
    "What are the top words indicative of a positive or a negative review? Let's find out:\n",
    "\n",
    "- get the features names from the `vectorizer` using the `.get_feature_names` method\n",
    "- get the features importances from the Logistic Regression using the `.coef_` attribute\n",
    "- wrap the coefficients in a Pandas series, with the names as index and rank them by value\n",
    "- select the top and bottom 20 features and print them\n",
    "- combine the top features into a single list of keywords and name it `top_features`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text exploration with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lBw6pkgWaH4h"
   },
   "outputs": [],
   "source": [
    "positive_reviews_concat = ' '.join(pos_rev)\n",
    "negative_reviews_concat = ' '.join(neg_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lgLfN4TDnh7A"
   },
   "outputs": [],
   "source": [
    "all_reviews = positive_reviews_concat + negative_reviews_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "14zmRSQAZJ0G"
   },
   "outputs": [],
   "source": [
    "all_text = nltk.text.Text(all_reviews.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "woaupkOPYgpE",
    "outputId": "01630a23-6e36-472e-dec9-9adcf3e828b1"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "all_text.dispersion_plot(top_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "1K7OMlWUZ1FT",
    "outputId": "c6d54f06-04a7-4c77-f05b-fdf3972f0f24"
   },
   "outputs": [],
   "source": [
    "all_text.concordance('enjoyable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 463
    },
    "colab_type": "code",
    "id": "aXOEs-wLoPwU",
    "outputId": "7781a828-a720-4c75-bb71-0850553a2cc5"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "all_text.plot(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FF8piITHovPW"
   },
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "2b9b6af749cf4264ae56eb669ecb0ec8",
      "6eb55b52f92c42699a79d7063598e7c1",
      "86e11e268e734b17bc5e0b1808fdfb29",
      "a52d5dfb472246ffa116930bd9acdfab",
      "01d1003d56aa4852a64ac0ea0cbe5180",
      "f8ee67fd25004b92bbc3495aa0632f1e",
      "fdd88303e15447c29aa6ae1fb92fb9df",
      "eece40336f3144d6b357fedfb8b83dfd"
     ]
    },
    "colab_type": "code",
    "id": "Ur940onyqK9_",
    "outputId": "41b415dd-570b-40a4-f1e9-2f83f8a49d61"
   },
   "outputs": [],
   "source": [
    "tokens = all_reviews.lower().split()\n",
    "\n",
    "clean_tokens = [t for t in tqdm_notebook(tokens) if t not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E-y79XYKpdxU"
   },
   "outputs": [],
   "source": [
    "all_text_lower = nltk.text.Text(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "colab_type": "code",
    "id": "07FKrXn-p_RJ",
    "outputId": "aeded119-89d0-4bbf-c9d7-c61923ffcaec"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "all_text_lower.plot(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pj63FN2Ruu9P"
   },
   "outputs": [],
   "source": [
    "class LemmaTokenizer:\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_tokenizer = LemmaTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_stop_words = list(np.unique(lemma_tokenizer(' '.join(stop_words))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Improve the TFIDF vectorizer\n",
    "\n",
    "Armed with the knowledge acquired in the text analysis, try to improve the configuration of the `TfidfVectorizer`. \n",
    "\n",
    "```python\n",
    "vectorizer = TfidfVectorizer(# YOUR CODE HERE\n",
    ")\n",
    "```\n",
    "\n",
    "- Things you could consider:\n",
    "    - increasing the number of features\n",
    "    - enforcing lowercase\n",
    "    - filtering stop words\n",
    "    - increasing the ngram range\n",
    "    - using the `lemma_tokenizer` defined above\n",
    "- Use the vectorizer to fit and transform the documents\n",
    "- Re-train the `LogisticRegression` model\n",
    "- Did the score improve?\n",
    "- Print out 10 false positives and 10 false negatives and see if you can spot any pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOJWB9s6S9wS5YLk8la7mLZ",
   "include_colab_link": true,
   "name": "Natural_Language_Processing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
