{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/zerotodeeplearning/ztdl-masterclasses/blob/master/solutions_do_not_open/Image_Classification_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2bwH96hViwS7"
   },
   "source": [
    "## Learn with us: www.zerotodeeplearning.com\n",
    "\n",
    "Copyright © 2021: Zero to Deep Learning ® Catalit LLC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bFidPKNdkVPg"
   },
   "outputs": [],
   "source": [
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DvoukA2tkGV4"
   },
   "source": [
    "# Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "pSabm4z-4j2q",
    "outputId": "86e9aaed-a845-4bf4-cb91-9274832cebe0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iHaepYAZ4y7D"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from tensorflow.keras.datasets import mnist, fashion_mnist, cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uQkUwBfdCJxl"
   },
   "source": [
    "### Helper functions\n",
    "Lets define a few helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LVnqDqap5RaV"
   },
   "outputs": [],
   "source": [
    "def describe_dataset(name, X_train, X_test, y_train, y_test):\n",
    "  xtrs = X_train.shape\n",
    "  xtes = X_test.shape\n",
    "  percent = np.round(100 * xtes[0] / (xtes[0] + xtrs[0]), 2)\n",
    "  dtype = X_train.dtype\n",
    "  m = X_train.min()\n",
    "  M = X_train.max()\n",
    "  print(\"\"\"\n",
    "\\033[1mDataset: {name}\n",
    "==========================================\\033[0m\n",
    "\n",
    "The feature tensors X_train and X_test have \\033[1m{axes} axes\\033[0m.\n",
    "  \n",
    "X_train.shape:\\t {xtrs}\n",
    "There are {trimg} images in the training set.\n",
    "\n",
    "X_test.shape:\\t {xtes}\n",
    "There are {teimg} images in the training set.\n",
    "\n",
    "Test size is {percent}% of total.\n",
    "\n",
    "Each image has {pix} pixels.\n",
    "\n",
    "Pixels are \\033[1m{dtype} values\\033[0m  between {m} and {M}\n",
    "\n",
    "y_train.shape:\\t {ytrs}\n",
    "y_test.shape:\\t {ytes}\n",
    "\n",
    "There are \\033[1m{cls} classes\\033[0m in the dataset.\n",
    "  \n",
    "  \"\"\".format(name=name,\n",
    "             axes=len(xtrs),\n",
    "             xtrs=xtrs,\n",
    "             trimg=xtrs[0],\n",
    "             xtes=xtes,\n",
    "             teimg=xtes[0],\n",
    "             percent=percent,\n",
    "             pix=xtrs[1:],\n",
    "             dtype=dtype,\n",
    "             m=m,\n",
    "             M=M,\n",
    "             ytrs=y_train.shape,\n",
    "             ytes=y_test.shape,\n",
    "             cls=len(np.unique(y_train))\n",
    "             ))\n",
    "\n",
    "def flatten_images(X_train, X_test):\n",
    "  Ntr = len(X_train)\n",
    "  Nte = len(X_test)\n",
    "  return X_train.reshape(Ntr, -1), X_test.reshape(Nte, -1)\n",
    "\n",
    "def load_images_dataset(option='scikit_digits', flatten=False):\n",
    "  if option=='scikit_digits':\n",
    "    X, y = load_digits(return_X_y=True)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=0)\n",
    "    name = \"Scikit Learn digits\"\n",
    "  elif option=='keras_digits':\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "    name = \"Keras MNIST digits\"\n",
    "  elif option=='keras_fashion':\n",
    "    (X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "    name = \"Keras Fashion MNIST clothes.\\nclass_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\"\n",
    "  elif option=='keras_cifar':\n",
    "    (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "    name = \"Keras Cifar10 objects\"\n",
    "  else:\n",
    "    raise ValueError(f\"{option} is not a valid option.\")\n",
    "\n",
    "  if flatten:\n",
    "    X_train, X_test = flatten_images(X_train, X_test)\n",
    "  describe_dataset(name, X_train, X_test, y_train, y_test)\n",
    "  return X_train, X_test, y_train, y_test\n",
    "\n",
    "def display_few_images(X, y, cmap=None, asarray=False):\n",
    "  n_classes = 10\n",
    "  n_rows = 4\n",
    "\n",
    "  print(f\"Displaying {n_classes*n_rows} images\", end='')\n",
    "  if asarray:\n",
    "    print(f\" as flattened arrays\")\n",
    "  else:\n",
    "    print()\n",
    "\n",
    "  plt.figure(figsize=(14, 5))\n",
    "  for i in range(n_classes):\n",
    "    imgs = X[y.ravel() == i][:n_rows]\n",
    "    labels = y[y.ravel() == i][:n_rows]\n",
    "    for j in range(n_rows):\n",
    "      img = imgs[j]\n",
    "      s = img.shape\n",
    "      if len(s)==1:\n",
    "        r = int(np.sqrt(s))\n",
    "        img = img.reshape(r, r)\n",
    "      plt.subplot(4, 10, j*n_classes+i+1)\n",
    "      if asarray:\n",
    "        plt.plot(img.ravel())\n",
    "      else:\n",
    "        plt.imshow(img, cmap=cmap)\n",
    "      plt.axis('off')\n",
    "      if j == 0:\n",
    "        plt.title(str(labels[j]))\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mxn7Mr5QCOfO"
   },
   "source": [
    "### Digits dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "w8vl9mMm5R-2",
    "outputId": "de84e30f-ae09-4f4a-ef3e-bd3ccb328a7e"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_images_dataset('scikit_digits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "colab_type": "code",
    "id": "cfoVwP7MBgyP",
    "outputId": "b2fb0d43-ded9-4396-80f3-5bcc16a3a69c"
   },
   "outputs": [],
   "source": [
    "display_few_images(X_train, y_train, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "colab_type": "code",
    "id": "a6ogqjoWJxhH",
    "outputId": "de745f45-9489-45f7-9f57-bb31deda6d0a"
   },
   "outputs": [],
   "source": [
    "display_few_images(X_train, y_train, asarray=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ezkXKCZF-GCt"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M5vbpX_U_qr7"
   },
   "outputs": [],
   "source": [
    "def train_eval_scikit(model):\n",
    "  model.fit(X_train, y_train)\n",
    "  train_score = model.score(X_train, y_train)\n",
    "  test_score = model.score(X_test, y_test)\n",
    "  print(\"Train score:\\t {:0.3}\".format(train_score))\n",
    "  print(\"Test score:\\t {:0.3}\".format(test_score))\n",
    "\n",
    "\n",
    "def train_eval_tf(model, epochs=5, batch_size=32):\n",
    "  h = model.fit(X_train, y_train, epochs=epochs, \n",
    "                batch_size=batch_size, validation_split=0.1)\n",
    "  _, train_score = model.evaluate(X_train, y_train, verbose=0)\n",
    "  _, test_score = model.evaluate(X_test, y_test, verbose=0)\n",
    "  print(\"Train score:\\t {:0.3}\".format(train_score))\n",
    "  print(\"Test score:\\t {:0.3}\".format(test_score))\n",
    "  pd.DataFrame(h.history).plot()\n",
    "  plt.ylim(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "eQb0DOe1_CFM",
    "outputId": "17ec3e6a-a259-4ddb-93e0-b6bba195d600"
   },
   "outputs": [],
   "source": [
    "train_eval_scikit(LogisticRegression(solver='liblinear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "akqU3UG0_EaF",
    "outputId": "fdd84900-970e-476a-f298-a2c11db5616d"
   },
   "outputs": [],
   "source": [
    "train_eval_scikit(GradientBoostingClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MRVlHmQIAxxK"
   },
   "source": [
    "### Exercise 1\n",
    "Load the dataset `'keras_digits'` using the `load_images_dataset` function and train a model.\n",
    "\n",
    "- Read the description printed by the `load_images_dataset` function and make sure you understand all of it.\n",
    "- Compare the description in the cases of `flatten=True` and `flatten=False`. Which of the two are you going to use?\n",
    "- Display a few images using the `display_few_images`, make sure you understand how they are\n",
    "- Display a few plots using the option `asarray=True`. Do plots with the same label look similar?\n",
    "- Use the `train_eval_scikit` function to evaluate the performance of a `LogisticRegression` model on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "HF8WRSjl_F2n",
    "outputId": "998eaad0-04f6-4881-ee01-5d89ec81e007",
    "tags": [
     "solution",
     "empty"
    ]
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_images_dataset('keras_digits', flatten=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "colab_type": "code",
    "id": "9QY5hZHm79tI",
    "outputId": "fddfdf00-04d7-488a-ecbb-d9b5e9f9e50e",
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "display_few_images(X_train, y_train, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "colab_type": "code",
    "id": "yigafnNXKohJ",
    "outputId": "7ea8a654-eb7d-4b69-a408-c4ec6e69d043",
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "display_few_images(X_train, y_train, asarray=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "IhPb_EgD_IXP",
    "outputId": "1bceb8d7-9119-436b-9bdc-0c0421c55c4e",
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "train_eval_scikit(LogisticRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z2ua3vRdCHal"
   },
   "source": [
    "### Exercise 2: Neural network model\n",
    "\n",
    "Design a simple fully connected neural network model using the `Sequential` API and use the `train_eval_tf` function to assess its performance on the MNIST dataset\n",
    "\n",
    "- The model architecture should include:\n",
    "  - An intial `Rescaling` layer to scale the pixel values by `1/255.` so that they are values in the interval `[0, 1]`.\n",
    "  - Any number of hidden layers. Make sure to use activation functions\n",
    "  - A final `Dense` layer with 10 nodes and a softmax\n",
    "- Compile the model, use an optimizer of your choice and the `sparse_categorical_crossentropy` loss\n",
    "\n",
    "Your code should look like:\n",
    "\n",
    "```python\n",
    "model = Sequential([\n",
    "  # YOUR CODE HERE\n",
    "  # ...\n",
    "])\n",
    "\n",
    "model.compile(# YOUR CODE HERE)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "604nxPKjBMwn"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a4u-EAmDBsVz",
    "tags": [
     "solution",
     "empty"
    ]
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "  Rescaling(scale=1/255.),\n",
    "  Dense(512, activation='relu'),\n",
    "  Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 473
    },
    "colab_type": "code",
    "id": "68I7UtE2D4E6",
    "outputId": "2193e1cc-5222-4c6c-9aa3-a0b0f4bd6126",
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "train_eval_tf(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AcjTE3BoHWwB"
   },
   "source": [
    "### Fashion MNIST & Cifar10 Datasets\n",
    "\n",
    "The MNIST dataset is quite easy. Let's look at a couple of more interesting datasets: Fashion MNIST and Cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "colab_type": "code",
    "id": "ZL_ISOcJEuqr",
    "outputId": "87f63a77-54d1-4082-eb42-83de440b0965"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_images_dataset('keras_fashion', flatten=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "colab_type": "code",
    "id": "8mdl4njmFafh",
    "outputId": "797216d3-b6a8-4103-afea-0c51b98c61cf"
   },
   "outputs": [],
   "source": [
    "display_few_images(X_train, y_train, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "colab_type": "code",
    "id": "ATgMcvLrLBYt",
    "outputId": "8f7ea22c-9a28-4dd1-cd51-60787cfdf0c0"
   },
   "outputs": [],
   "source": [
    "display_few_images(X_train, y_train, asarray=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 473
    },
    "colab_type": "code",
    "id": "hW7I5_NsFbCL",
    "outputId": "7334a166-e177-4c41-8500-431b4a76cc3b"
   },
   "outputs": [],
   "source": [
    "train_eval_tf(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "ChR2tZJoFeMe",
    "outputId": "c8a27c59-f734-4adf-dc5d-ec6fade602dd"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_images_dataset('keras_cifar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "colab_type": "code",
    "id": "9vNJQaQm-6WO",
    "outputId": "a794b5f0-9dd9-41c9-e7f5-b331e0f5a01e"
   },
   "outputs": [],
   "source": [
    "display_few_images(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "colab_type": "code",
    "id": "HfA7HEp6LGh0",
    "outputId": "6510c2d8-532f-4fe6-acd9-bae6e5035c04"
   },
   "outputs": [],
   "source": [
    "display_few_images(X_train, y_train, asarray=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "exY3ztLFJ3dw"
   },
   "source": [
    "### Exercise 3: Neural network for 3D data with functional API\n",
    "\n",
    "Define a new neural network using the functional API and make it work with 3D input data. \n",
    "\n",
    "- The architecture will be similar to the previous model\n",
    "- You will need to introduce a `Flatten` layer at the beginning of the network so that the images are flattened to arrays before being passed to the inner layers\n",
    "- Introduce some additional inner layers to give the network enough freedom to learn\n",
    "- Bonus point if you define an auxiliary model that has the second-to-last layer as output for inspection. Set the size of this layer to 256\n",
    "- Double bonus points if you use a dimensionality reduction technique to reduce the 256 outputs to 3 dimensions and visualize the results on a scatter plot.\n",
    "\n",
    "\n",
    "You will notice that training proceeds quite slowly with this dataset. Try the following things:\n",
    "\n",
    "- Increase the `batch_size` in the `train_eval_tf` function\n",
    "- Switch the backend of the notebook from CPU to GPU usin the `Edit->Notebook Settings` menu and re-run the whole notebook. You should see a speed increase\n",
    "\n",
    "Your code should look like:\n",
    "\n",
    "```python\n",
    "inputs = ...\n",
    "# YOUR CODE HERE\n",
    "#...\n",
    "outputs = ...\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model1 = Model(inputs=inputs, outputs=x)\n",
    "\n",
    "model.compile(# YOUR CODE HERE)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "knsMwGvU_YJm"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Flatten, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from sklearn.decomposition import KernelPCA\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3JKuj_CY-9He",
    "tags": [
     "solution",
     "emtpy"
    ]
   },
   "outputs": [],
   "source": [
    "inputs = Input(shape=(32, 32, 3))\n",
    "x = Flatten()(inputs)\n",
    "x = Rescaling(scale=1/255.)(x)\n",
    "x = Dense(2048, activation='relu')(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "outputs = Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model1 = Model(inputs=inputs, outputs=x)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 847
    },
    "colab_type": "code",
    "id": "GxH3CDj7_eeC",
    "outputId": "550117fb-870b-41ae-be01-45134002f620",
    "scrolled": true,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "train_eval_tf(model, batch_size=128, epochs=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v-HxJWKURoXp",
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "n_points = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yQrblcwwRXEt",
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "bottlenecks = model1(X_test[:n_points])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VIJO7f34RdXp",
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "H = KernelPCA(n_components=3).fit_transform(bottlenecks)\n",
    "\n",
    "X_pca = pd.DataFrame(H, columns=['c1', 'c2', 'c3'])\n",
    "\n",
    "X_pca['label'] = y_test[:n_points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "colab_type": "code",
    "id": "ZeeZ-IQORq5A",
    "outputId": "6dd069d3-481f-4456-ab10-48a5e8dd1033",
    "scrolled": false,
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "px.scatter_3d(X_pca, x='c1', y='c2',z='c3', color='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lfUvuLt8R9w7",
    "outputId": "b89848b9-0281-4772-d1bc-bf8c9fdbb5bb",
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "# Save test embeddings for visualization in projector\n",
    "np.savetxt(\"vecs.tsv\", bottlenecks, delimiter='\\t')\n",
    "\n",
    "with open('meta.tsv', 'w', encoding='utf-8') as out_m:\n",
    "  for labels in y_test[:n_points]:\n",
    "      [out_m.write(str(x) + \"\\n\") for x in labels]\n",
    "\n",
    "try:\n",
    "  from google.colab import files\n",
    "  files.download('vecs.tsv')\n",
    "  files.download('meta.tsv')\n",
    "  print(\"Now go to https://projector.tensorflow.org/ and upload your files\")\n",
    "except:\n",
    "  print(\"Couldn't download files\")\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "colab": {
   "authorship_tag": "ABX9TyOJWB9s6S9wS5YLk8la7mLZ",
   "include_colab_link": true,
   "name": "Image_Classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
